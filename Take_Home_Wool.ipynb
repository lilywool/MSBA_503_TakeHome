{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d5bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from ultralytics import YOLO\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3128cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Image Sources\n",
    "image_urls = [\n",
    "\n",
    "    \"https://ultralytics.com/images/zidane.jpg\",\n",
    "    \"https://ultralytics.com/images/bus.jpg\",\n",
    "    \n",
    "\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Red_Kitten_01.jpg\",\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Axis_axis_crossing_the_road.JPG\",\n",
    "    \n",
    "\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Wooden_table_and_chairs_on_a_balcony_over_the_Mekong_at_sunrise_in_Don_Det_Si_Phan_Don_Laos.jpg\",\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Lava_lamp_on_windowsill.jpg\",\n",
    "    \n",
    "\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Sukhoi_SuperJet_100_(5114478300).jpg\",\n",
    " \n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Water_reflection_of_mountains_and_hut_in_a_paddy_field_with_blue_sky_in_Vang_Vieng,_Laos.jpg\",\n",
    "\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Bowl_of_fruit.jpg\",\n",
    "\n",
    "    \"https://commons.wikimedia.org/wiki/Special:FilePath/Street_Traffic_In_Barcelona_(166082009).jpeg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Models\n",
    "# Model A: YOLOv8 (nano version for speed)\n",
    "yolo_model = YOLO('yolov8n.pt') \n",
    "\n",
    "# Model B: Faster R-CNN\n",
    "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "frcnn_model = fasterrcnn_resnet50_fpn(weights=weights)\n",
    "frcnn_model.eval()\n",
    "frcnn_transform = weights.transforms()\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "976dbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Image_1...\n",
      "Processed Image_2...\n",
      "Processed Image_3...\n",
      "Processed Image_4...\n",
      "Processed Image_5...\n",
      "Processed Image_6...\n",
      "Processed Image_7...\n",
      "Processed Image_8...\n",
      "Processed Image_9...\n",
      "Processed Image_10...\n"
     ]
    }
   ],
   "source": [
    "#Store Data\n",
    "results_data = []  # <--- Clears the list so you don't get duplicates\n",
    "\n",
    "#Processing\n",
    "for i, url in enumerate(image_urls):\n",
    "    try:\n",
    "        # 1. Load Image\n",
    "        response = requests.get(url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        img_raw = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img_name = f\"Image_{i+1}\"\n",
    "        \n",
    "        # 2. Deep Learning\n",
    "        # A. YOLOv8\n",
    "        start_time = time.time()\n",
    "        yolo_results = yolo_model(img_raw, verbose=False)\n",
    "        yolo_time = time.time() - start_time\n",
    "        \n",
    "        y_count = len(yolo_results[0].boxes)\n",
    "        y_conf = yolo_results[0].boxes.conf.mean().item() if y_count > 0 else 0\n",
    "\n",
    "        # B. Faster R-CNN\n",
    "        img_tensor = frcnn_transform(img_raw).unsqueeze(0)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            frcnn_results = frcnn_model(img_tensor)\n",
    "        frcnn_time = time.time() - start_time\n",
    "        \n",
    "        # Extract R-CNN Data\n",
    "        pred_scores = frcnn_results[0]['scores']\n",
    "        high_conf_indices = [idx for idx, score in enumerate(pred_scores) if score > 0.5]\n",
    "        \n",
    "        r_count = len(high_conf_indices)\n",
    "        r_conf = pred_scores[high_conf_indices].mean().item() if r_count > 0 else 0\n",
    "        \n",
    "        # Non-Deep Learning\n",
    "        # Calculate Average Image Brightness\n",
    "        img_array = np.array(img_raw)\n",
    "        avg_brightness = round(np.mean(img_array), 2)\n",
    "        \n",
    "        # Save Results\n",
    "        results_data.append({\n",
    "            \"Image\": img_name, \n",
    "            \"Model\": \"YOLOv8\", \n",
    "            \"Time (sec)\": round(yolo_time, 4),\n",
    "            \"Objects Detected\": y_count, \n",
    "            \"Avg Probability\": round(y_conf, 4),\n",
    "            \"Brightness (Non-DL)\": avg_brightness\n",
    "        })\n",
    "        \n",
    "        results_data.append({\n",
    "            \"Image\": img_name, \n",
    "            \"Model\": \"Faster R-CNN\", \n",
    "            \"Time (sec)\": round(frcnn_time, 4),\n",
    "            \"Objects Detected\": r_count, \n",
    "            \"Avg Probability\": round(r_conf, 4),\n",
    "            \"Brightness (Non-DL)\": avg_brightness\n",
    "        })\n",
    "        \n",
    "        print(f\"Processed {img_name}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c871751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Table:\n",
      "       Image         Model  Time (sec)  Objects Detected  Avg Probability  \\\n",
      "1    Image_1  Faster R-CNN      1.8070                 8           0.8444   \n",
      "0    Image_1        YOLOv8      0.0386                 3           0.6486   \n",
      "3    Image_2  Faster R-CNN      1.5841                 5           0.9880   \n",
      "2    Image_2        YOLOv8      0.0468                 6           0.6556   \n",
      "5    Image_3  Faster R-CNN      1.7293                 1           0.9912   \n",
      "4    Image_3        YOLOv8      0.0975                 2           0.6288   \n",
      "7    Image_4  Faster R-CNN      1.6744                 1           0.7379   \n",
      "6    Image_4        YOLOv8      0.0873                 1           0.8899   \n",
      "9    Image_5  Faster R-CNN      1.6775                 6           0.7576   \n",
      "8    Image_5        YOLOv8      0.0866                 3           0.6778   \n",
      "11   Image_6  Faster R-CNN      1.9125                 6           0.6877   \n",
      "10   Image_6        YOLOv8      0.3015                 3           0.5745   \n",
      "13   Image_7  Faster R-CNN      1.6867                 1           0.9982   \n",
      "12   Image_7        YOLOv8      0.1051                 1           0.9308   \n",
      "15   Image_8  Faster R-CNN      1.9026                 1           0.9501   \n",
      "14   Image_8        YOLOv8      0.2337                 0           0.0000   \n",
      "17   Image_9  Faster R-CNN      1.2963                11           0.8708   \n",
      "16   Image_9        YOLOv8      0.0462                10           0.5721   \n",
      "19  Image_10  Faster R-CNN      1.6040                40           0.7892   \n",
      "18  Image_10        YOLOv8      0.0514                18           0.4288   \n",
      "\n",
      "    Brightness (Non-DL)  \n",
      "1                 59.65  \n",
      "0                 59.65  \n",
      "3                117.10  \n",
      "2                117.10  \n",
      "5                106.88  \n",
      "4                106.88  \n",
      "7                122.31  \n",
      "6                122.31  \n",
      "9                 70.91  \n",
      "8                 70.91  \n",
      "11                82.61  \n",
      "10                82.61  \n",
      "13               177.24  \n",
      "12               177.24  \n",
      "15               142.71  \n",
      "14               142.71  \n",
      "17               103.55  \n",
      "16               103.55  \n",
      "19               160.32  \n",
      "18               160.32  \n"
     ]
    }
   ],
   "source": [
    "# Output Table\n",
    "df = pd.DataFrame(results_data)\n",
    "\n",
    "# Sort strictly by Image Number (1, 2, 3... 10)\n",
    "df['sort_key'] = df['Image'].apply(lambda x: int(x.split('_')[1]))\n",
    "df = df.sort_values(by=['sort_key', 'Model'])\n",
    "df = df.drop(columns=['sort_key'])\n",
    "\n",
    "print(\"\\nAnalysis Table:\")\n",
    "print(df)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"model_comparison_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
